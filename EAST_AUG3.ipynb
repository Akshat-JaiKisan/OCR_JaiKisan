{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EAST_AUG3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHXhpzok4+lEYEi56/kk8c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfFSYZ5SwL0i"
      },
      "source": [
        "# import the necessary packages\r\n",
        "\r\n",
        "from imutils.object_detection import non_max_suppression # no idea how this works\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import time\r\n",
        "import cv2\r\n",
        "from google.colab.patches import cv2_imshow # change this to cv2.imshow if its not running on colab\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "#tf.keras.preprocessing.image.random_rotation\r\n",
        "#FLAGS = tf.app.flags.FLAGS\r\n",
        "\r\n",
        "# Define necessary FLAGS\r\n",
        "\r\n",
        "\r\n",
        "padding_x = 5\r\n",
        "padding_y = 5\r\n",
        "\r\n",
        "data_augmentation = tf.keras.Sequential([layers.experimental.preprocessing.RandomRotation(0.02)])\r\n",
        "\r\n",
        "image = cv2.imread('Text_Augmented4.jpg')\r\n",
        "\r\n",
        "orig = image.copy()\r\n",
        "(H, W) = image.shape[:2]\r\n",
        "print(H,W) # (2000,4000)\r\n",
        "(newH, newW) = (320, 320) # multiples of 320\r\n",
        "\r\n",
        "# reducing the size of the images helps in faster edge detection and contours\r\n",
        "\r\n",
        "factor_W = W / float(newW) # remember the scaling factor involved to be used later\r\n",
        "factor_H = H / float(newH)\r\n",
        "\r\n",
        "image = cv2.resize(image, (newW, newH))\r\n",
        "(H, W) = image.shape[:2] # new H , W\r\n",
        "\r\n",
        "layerNames = [\"feature_fusion/Conv_7/Sigmoid\",\"feature_fusion/concat_3\"] # last two layers of the pretrained model\r\n",
        "\r\n",
        "print(\"East Text Detector is starting ...\")\r\n",
        "model = cv2.dnn.readNet(\"frozen_east_text_detection.pb\") # read the pretrained model \r\n",
        "  # construct a blob from the image and then perform a forward pass of\r\n",
        "# the model to obtain the two output layer sets\r\n",
        "\r\n",
        "\r\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),(123.68, 116.78, 103.94), swapRB=True, crop=False) # the tuple is the mean derived from tensorflow hub \r\n",
        "  #scaling of the images is not being done here...\r\n",
        "  # The mean value is beyond me\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "model.setInput(blob)\r\n",
        "(scores, geometry) = model.forward(layerNames) # from tensorflow website\r\n",
        "\r\n",
        "print(\"Shape of the score volume is ...\") # (1,1,80,80) (number of images , value associated , row , cols)\r\n",
        "print(scores.shape)\r\n",
        "print('Geometry that we get is ....')\r\n",
        "print(geometry.shape) # (1,5,80,80) (number of images , tensor associated , row , cols)\r\n",
        "(numR, numC) = scores.shape[2:4]\r\n",
        "\r\n",
        "rects = []\r\n",
        "confidences = []\r\n",
        "for y in range(0, numR): # will go up vertically na so it is the y coordinate of your rectangles....\r\n",
        "\r\n",
        "    \r\n",
        "  scoresData = scores[0, 0, y]\r\n",
        "  print(\"scoresData shape is..\")\r\n",
        "  print(scoresData.shape) # (80,) for a particular y the xs\r\n",
        "  x0 = geometry[0, 0, y]\r\n",
        "  x1 = geometry[0, 1, y]\r\n",
        "  x2 = geometry[0, 2, y]\r\n",
        "  x3 = geometry[0, 3, y]\r\n",
        "  theta = geometry[0, 4, y]\r\n",
        "\r\n",
        "  for x in range(0, numC):\r\n",
        "        # if our score does not have sufficient probability, ignore it\r\n",
        "      if scoresData[x] < 0.5:\r\n",
        "          continue\r\n",
        "            \r\n",
        "      (newX, newY) = (x * 4.0, y * 4.0) # according to the paper\r\n",
        "      angle = theta[x]\r\n",
        "      cos = np.cos(angle)\r\n",
        "      sin = np.sin(angle)\r\n",
        "\r\n",
        "      h = x0[x] + x2[x]\r\n",
        "      w = x1[x] + x3[x]\r\n",
        "\r\n",
        "      endX = int(newX + (cos * x1[x]) + (sin * x2[x]))\r\n",
        "      endY = int(newY - (sin * x1[x]) + (cos * x2[x]))\r\n",
        "      startX = int(endX - w)\r\n",
        "      startY = int(endY - h)\r\n",
        "\r\n",
        "      rects.append((startX, startY, endX, endY))\r\n",
        "      confidences.append(scoresData[x])\r\n",
        "        \r\n",
        "# apply non-maxima suppression to suppress weak, overlapping bounding\r\n",
        "# boxes\r\n",
        "boxes = non_max_suppression(np.array(rects), probs=confidences)\r\n",
        "\r\n",
        "# loop over the bounding boxes\r\n",
        "i = 0\r\n",
        "for (startX, startY, endX, endY) in boxes:\r\n",
        "  startX = int(startX * factor_W) # scale them up again using the scaling factor\r\n",
        "  startY = int(startY * factor_H) # scale them up again using the scaling factor\r\n",
        "  endX = int(endX * factor_W) # \r\n",
        "  endY = int(endY * factor_H) #\r\n",
        "\r\n",
        "  cv2.imwrite(\"Text_{}.jpg\".format(i+1) , orig[startY-padding_y:endY + padding_y , startX-padding_x:endX+padding_y])\r\n",
        "  cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\r\n",
        "\r\n",
        "    \r\n",
        "  i = i+1\r\n",
        "  end = time.time()\r\n",
        "#print('Time Taken for data number{} is ..'.format(pan))\r\n",
        "print(end-start)\r\n",
        "cv2_imshow(orig)\r\n",
        "image = tf.expand_dims(image, 0)\r\n",
        "image = data_augmentation(image)[0]\r\n",
        "image = np.array(image) # number of times data augmentation shall be applied on the given image\r\n",
        "  \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}